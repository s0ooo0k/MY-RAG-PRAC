{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0e6a944",
   "metadata": {},
   "source": [
    "# MYSQL, LangCahin, Tour DB ì´ìš©í•œ RAG\n",
    "1. MySQL -> ê´€ê´‘ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "2. LangChainìœ¼ë¡œ í…ìŠ¤íŠ¸ ìª¼ê°œê¸° + ë²¡í„°í™” + Chroma ì €ì¥\n",
    "3. ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥ -> ìœ ì‚¬í•œ ê´€ê´‘ ì •ë³´ ê²€ìƒ‰\n",
    "4. LangChain + Gemini ë¡œ ë‹µë³€ ìƒì„±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71decac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mysql-connector-python sqlalchemy\n",
    "%pip install langchain langchain-google-genai chromadb python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ea6d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#langchain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# DB ì—°ê²° ìœ„í•œ SQLAlchemy ì—”ì§„ ë§Œë“¤ê¸°\n",
    "# engine -> MySQLê³¼ ì—°ê²°ëœ ê°€ìƒ ì—°ê²° ê°ì²´\n",
    "engine = create_engine(os.getenv(\"DB_URL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a86a16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TABLE] Content, PET_TOUR_INFO ì¡°ì¸, ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\n",
    "        \"\"\"\n",
    "        SELECT\n",
    "            c.contentid,\n",
    "            c.title,\n",
    "            c.overview,\n",
    "            c.addr1,\n",
    "            c.addr2,\n",
    "            pt.rela_acdnt_risk_mtr,\n",
    "            pt.acmpy_type_cd,\n",
    "            pt.rela_poses_fclty,\n",
    "            pt.etc_acmpy_info,\n",
    "            pt.acmpy_need_mtr\n",
    "        FROM Content c\n",
    "        JOIN Pet_Tour_Info pt ON c.contentid=pt.contentid\n",
    "\"\"\"))\n",
    "    \n",
    "# ì¿¼ë¦¬ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì¡°í•©í•˜ê¸°\n",
    "data = []\n",
    "for row in result:\n",
    "    text_parts = [\n",
    "        f\"[ì´ë¦„] {row.title}\",\n",
    "        f\"[ì„¤ëª…] {row.overview}\",\n",
    "        f\"[ì£¼ì†Œ] {row.addr1 or ''} {row.addr2 or ''}\",\n",
    "    ]\n",
    "    \n",
    "    # ë°˜ë ¤ë™ë¬¼ ê´€ë ¨ ì •ë³´ ì¶”ê°€\n",
    "    if row.acmpy_type_cd:\n",
    "        text_parts.append(f\"[ë™ë°˜ìœ í˜•] {row.acmpy_type_cd}\")\n",
    "    if row.rela_acdnt_risk_mtr:\n",
    "        text_parts.append(f\"[ìœ„í—˜ìš”ì†Œ] {row.rela_acdnt_risk_mtr}\")\n",
    "    if row.rela_poses_fclty:\n",
    "        text_parts.append(f\"[êµ¬ë¹„ì‹œì„¤] {row.rela_poses_fclty}\")\n",
    "    if row.etc_acmpy_info:\n",
    "        text_parts.append(f\"[ê¸°íƒ€ì •ë³´] {row.etc_acmpy_info}\")\n",
    "    if row.acmpy_need_mtr:\n",
    "        text_parts.append(f\"[ìœ ì˜ì‚¬í•­] {row.acmpy_need_mtr}\")\n",
    "        \n",
    "    combined_text=\" \".join(text_parts)\n",
    "    data.append(combined_text.strip())\n",
    "    \n",
    "# print(data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a4f1c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í…ìŠ¤íŠ¸ ì²­í‚¹\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# splitter ì´ìš©í•˜ì—¬ ìë¥´ê¸°\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    # ì²­í¬ ì‚¬ì´ì¦ˆ 300\n",
    "    chunk_size=300, \n",
    "    # ê²¹ì¹˜ëŠ” ê¸€ììˆ˜\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "# ì²­í¬ ë‚˜ëˆ„ê¸°\n",
    "docs = splitter.create_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "675b789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ë² ë”©(ë²¡í„°í™”)\n",
    "# text-multilingual-embedding-002 ëª¨ë¸ ì‚¬ìš©\n",
    "load_dotenv()\n",
    "embedding = GoogleGenerativeAIEmbeddings(\n",
    "    model='models/embedding-001'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4797def8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chroma Vector DBì— ë²¡í„°í™” ë‚´ìš© ì €ì¥\n",
    "# (í…ŒìŠ¤íŠ¸ìš©) ë¡œì»¬ì— ì €ì¥í•´ì„œ ë‹¤ìŒì— ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ -> ì¶”í›„ Qdrantë¡œ ì „í™˜\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    docs,\n",
    "    embedding=embedding,\n",
    "    persist_directory=\"./tour_pet\"        \n",
    ")\n",
    "\n",
    "vectorstore.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa9721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever > ì§ˆë¬¸ì— ê°€ê¹Œìš´ ë¬¸ì¥ ì°¾ê¸°\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "query = \"ê°•ì•„ì§€ë‘ ë†€ëŸ¬ê°€ê¸° ì¢‹ì€ ì„œìš¸ ê³µì› ìˆì–´?\"\n",
    "matched_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "for i, doc in enumerate(matched_docs[:3], 1):\n",
    "    print(f\"{i}: \\n{doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e6b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains import RetrievalQA\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# llm = ChatGoogleGenerativeAI(\n",
    "#       model=\"gemini-1.5-pro\")\n",
    "\n",
    "# qa_chain = RetrievalQA.from_chain_type(\n",
    "#     llm=llm,\n",
    "#     retriever=retriever,   # ê¸°ì¡´ Chroma retriever ì‚¬ìš©\n",
    "#     return_source_documents=True,  # ë‹µë³€ê³¼ í•¨ê»˜ ê·¼ê±° ë¬¸ì„œë„ ë°˜í™˜\n",
    "# )\n",
    "\n",
    "# query = \"ê°•ì•„ì§€ ì«‘ì«‘ì´ë‘ ê°™ì´ ê°ˆ ìˆ˜ ìˆëŠ” ì¸ì²œì— ìˆëŠ” ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ê°€ëŠ¥í•œ ê³µì›ì„ ì•Œë ¤ì¤˜. ê´€ê´‘ì§€ ì´ë¦„ë„ ê°™ì´ ì•Œë ¤ì¤˜.\"\n",
    "\n",
    "# result = qa_chain.invoke({\"query\": query})\n",
    "# print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5205b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_docs = [doc for doc in docs if \"ê°•ì›\" in doc.page_content]\n",
    "print(f\"ê°•ì› ì²­í¬: {len(filtered_docs)}\")\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "filtered_vectorstore = Chroma.from_documents(\n",
    "    filtered_docs,\n",
    "    embedding=embedding\n",
    ")\n",
    "filtered_retriever = filtered_vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5d2a005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Gemini LLM ì„¤ì •\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-pro\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0da0bf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¶: ë§ì¶¤ ì¥ì†Œë¥¼ ì¶”ì²œí•´ë“œë¦´ê²Œìš”!\n",
      "\n",
      "- ì¥ì†Œëª…: íœ˜ë‹‰ìŠ¤ í‰ì°½ ì½˜ë„\n",
      "- ì„¤ëª…: ë‹¤ì–‘í•œ ë¶€ëŒ€ì‹œì„¤(ìˆ˜ì˜ì¥, ë³¼ë§ì¥, ë‹¹êµ¬ì¥, ë§ˆì‚¬ì§€, í¸ì˜ì  ë“±)ì„ ê°–ì¶˜ ê³ ê¸‰ ì½˜ë„. ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ê°€ëŠ¥ ì—¬ë¶€ëŠ” ëª…ì‹œë˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ, ì½˜ë„ì— ì§ì ‘ ë¬¸ì˜ í•„ìš”.\n",
      "- ì£¼ì†Œ: ê°•ì›íŠ¹ë³„ìì¹˜ë„ í‰ì°½êµ° ë´‰í‰ë©´ íƒœê¸°ë¡œ\n",
      "- ë°˜ë ¤ë™ë¬¼ ê´€ë ¨ ì •ë³´:  ë¬¸ì˜ í•„ìš”\n",
      "\n",
      "- ì¥ì†Œëª…: ë¬´ë¦‰ë„ì›ë©´ ìº í•‘ì¥ (ì´ë¦„ ë¶ˆëª…)\n",
      "- ì„¤ëª…: ìˆ˜ì˜ì¥, ë§¤ì , ë¯¸ë‹ˆê²Œì„ì¥ ë“± ë¶€ëŒ€ì‹œì„¤ì„ ê°–ì¶˜ ìº í•‘ì¥. ì¼ë¶€ êµ¬ì—­ ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ê°€ëŠ¥. ì£¼ë³€ì— ê³ ì”¨ë™êµ´, ì„ ëŒ, í•œë°˜ë„ì§€í˜• ë“± ê´€ê´‘ì§€ ìœ„ì¹˜.\n",
      "- ì£¼ì†Œ: ê°•ì›íŠ¹ë³„ìì¹˜ë„ ì˜ì›”êµ° ë¬´ë¦‰ë„ì›ë©´ ë„ì›ìš´í•™ë¡œ 475-10\n",
      "- ë°˜ë ¤ë™ë¬¼ ê´€ë ¨ ì •ë³´: ì¼ë¶€êµ¬ì—­ ë™ë°˜ ê°€ëŠ¥\n",
      "\n",
      "- ì¥ì†Œëª…: ë²•í¥ê³„ê³¡ ìº í•‘ì¥ (ì´ë¦„ ë¶ˆëª…)\n",
      "- ì„¤ëª…: ìº í•‘ ì¥ë¹„ ëŒ€ì—¬ ê°€ëŠ¥, 365ì¼ ìš´ì˜, ë°˜ë ¤ê²¬ ì…ì¥ ê°€ëŠ¥. ì£¼ë¥˜, ìŒë£Œ, ì‹í’ˆ ë“± íŒë§¤í•˜ëŠ” ë§¤ì  ìˆìŒ.\n",
      "- ì£¼ì†Œ: ê°•ì›íŠ¹ë³„ìì¹˜ë„ ì˜ì›”êµ° ë¬´ë¦‰ë„ì›ë©´ ë¬´ë¦‰ë²•í¥ë¡œ 968-12\n",
      "- ë°˜ë ¤ë™ë¬¼ ê´€ë ¨ ì •ë³´: ë°˜ë ¤ê²¬ ë™ë°˜ ê°€ëŠ¥\n",
      "\n",
      "\n",
      "ìœ„ ì„¸ ê³³ ì™¸ì— ì§ˆë¬¸ì— ì œì‹œëœ ì •ë³´ì—ëŠ” ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ê°€ëŠ¥í•œ íœì…˜, ìˆ™ì†Œ, í˜¸í…”, ëª¨í…” ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.  í‰ì°½/ì˜ì›” ì§€ì—­ì˜ ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ìˆ™ì†ŒëŠ” ì¶”ê°€ ê²€ìƒ‰ì„ í†µí•´ ì°¾ì•„ë³´ì‹œëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
      "\n",
      "\n",
      "**ì¶”ê°€ì ìœ¼ë¡œ, í‰ì°½ ê´€ê´‘ ì •ë³´:**\n",
      "\n",
      "í—ˆë¸Œë‚˜ë¼, ì›”ì •ì‚¬ ì „ë‚˜ë¬´ìˆ²ê¸¸, íš¨ì„ë‹¬ë¹›ì–¸ë•, ëŒ€ê´€ë ¹ì–‘ë–¼ëª©ì¥, ì˜¤ëŒ€ì‚°, ë°œì™•ì‚°ì¼€ì´ë¸”ì¹´ ë“±ì´ ìˆìœ¼ë©°, í‰ì°½ ê´€ê´‘íƒì‹œë¥¼ ì´ìš©í•˜ì—¬ í¸ë¦¬í•˜ê²Œ ì—¬í–‰ ê°€ëŠ¥í•©ë‹ˆë‹¤. (ë‹¨, ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ê°€ëŠ¥ ì—¬ë¶€ëŠ” íƒì‹œ ê¸°ì‚¬ë‹˜ê»˜ í™•ì¸ í•„ìš”)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ìœ ë„í˜• í”„ë¡¬í”„íŠ¸\n",
    "custom_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    ë‹¤ìŒ ì •ë³´ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”\n",
    "    {context}\n",
    "    \n",
    "    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë”°ë¼ ì ì ˆí•œ ì¥ì†Œë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶”ì²œí•´ì£¼ì„¸ìš”:\n",
    "    - ì¥ì†Œëª…: OOO\n",
    "    - ì„¤ëª…: ê°„ë‹¨í•œ ì„¤ëª…\n",
    "    - ì£¼ì†Œ: ê°€ëŠ¥í•˜ë©´ í¬í•¨\n",
    "    - ë°˜ë ¤ë™ë¬¼ ê´€ë ¨ ì •ë³´ : ìµœëŒ€í•œ í¬í•¨\n",
    "\n",
    "    ì§ˆë¬¸: {question}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "qa_chain_filtered = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=filtered_retriever,\n",
    "    chain_type_kwargs={\"prompt\": custom_prompt},\n",
    "    return_source_documents=True,\n",
    "    input_key=\"question\"\n",
    "    \n",
    ")\n",
    "\n",
    "query = \"ë§í‹°ì¦ˆì¦ˆ ì«‘ì«‘ì´ë‘ ê°™ì´ ê°ˆ ìˆ˜ ìˆëŠ” ê°•ì›ë„ì— ìˆëŠ” ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ê°€ëŠ¥í•œ íœì…˜, ìˆ™ì†Œ, í˜¸í…”, ëª¨í…”ì„ì„ ì•Œë ¤ì¤˜. ê´€ê´‘ì§€ ì´ë¦„ë„ ê°™ì´ ì•Œë ¤ì¤˜.\"\n",
    "result = qa_chain_filtered.invoke({\"question\": query})\n",
    "\n",
    "print(\"ğŸ¶: ë§ì¶¤ ì¥ì†Œë¥¼ ì¶”ì²œí•´ë“œë¦´ê²Œìš”!\\n\")\n",
    "print(result[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-application",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
